== Log Structured Merge Trees(LSM)

> 简单来说，LSM被设计来提供比传统的B+树或者ISAM更好的写操作吞吐量，通过消去随机的本地更新操作来达到这个目标(顺序读写快，随机读写慢)。


因为简单和高效，基于日志的策略在大数据之间越来越流行，同时他们也有一些缺点，从日志中读一些数据将会比写操作需要更多的时间，需要倒序扫描，直接找到所需要的内容。

这说明日志仅适用于一些简单的读场景：

. 数据是整体访问，像大部分数据库的WAL（write-ahead log）
. 知道明确的offset，比如在kafka中

所以需要更多的日志来为更复杂的读场景（比如按key或者range）提供高效的性能，这儿有4个方法可以完成这个，他们分别是：

. 二分查找：将文件数据有序保存，使用二分查找来完成特定key的查找。
. 哈希：用哈希将数据分割为不同的bucket
. B+树：使用B+树或者ISAM等方法，可以减少外部文件的读取
. 外部文件：将数据保存为日志，并创建一个hash或者查找树映射相关的文件

=== The Base LSM Algorithm

从概念上说，最基本的LSM是很简单的。将之前使用一个大的查找结构（造成随机读写，影响写性能），变换为将写操作顺序的保存到一些相似的有序文件（也就是sstable）中。所以每个文件包含短时间内的一些改动。因为文件是有序的，所以以后查找也会很快。文件是不可修改的，他们永远不会被更新，新的操作只会写到新的文件中。读操作检查很有的文件。通过周期性的合并这些文件来减少文件个数。

image::lsm.dio.svg[]

LSM的原理：将对数据的修改增量保存在内存中，达到指定大小限制之后批量把数据flush到磁盘中，磁盘中树定期可以做merge操作，合并成一棵大树，以优化读性能。不过读取的时候稍微麻烦一些，读取时看这些数据在内存中，如果未能命中内存，则需要访问较多的磁盘文件。


写入不占用磁盘的io，读取就能获取更长时间的磁盘io使用权，从而也可以提升读取效率。

### 附录

. 磁盘的理论速度 200-300 MB/s
. 支持copy-on-write tree（通过顺序在文件末尾重复写对结构来实现写操作，之前的树结构相关部分，包括最顶层节点都会变成孤节点。尽管通过这种方法避免了本地更新，但是因为每个操作都要重写树结构，放大了写操作，降低了写性能）。
. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.2782&rep=rep1&type=pdf[LSM 论文]